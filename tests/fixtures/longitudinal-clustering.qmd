---
title: "Longitudinal Clustering Methods for 50,000 Emergency Psychiatry Patients"
author: "Emergency Psychiatry Subtyping Project"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    theme: default
    code-fold: false
bibliography: references.bib
csl: https://www.zotero.org/styles/nature
---

## Introduction

This document reviews clustering methods appropriate for longitudinal clinical visit data from 50,000 emergency psychiatry patients (N ≈ 50,000 patients, 200,000 clinical visits, with approximately 10,000 features per observation).

Key challenges are:

1.  Uneven/irregular timing of conversations.\
2.  High rates of missingness.\
3.  Mixed data types (categorical + continuous).\
4.  Large scale: challenging to compute full subject × subject distance matrices without approximations.

## Longitudinal vs Non-Longitudinal Clustering

When clustering clinical data, it's important to distinguish between **longitudinal** and **non-longitudinal** approaches:

### Longitudinal Clustering

-   **Definition**: Analyzes data points collected over time for the same subjects, capturing temporal patterns and trajectories.
-   **Key considerations**:
    -   Temporal dependencies between observations must be modeled explicitly.
    -   Irregular time intervals between observations need special handling.
    -   Missing data patterns over time require appropriate statistical methods.
    -   Focus is on identifying patient trajectories or progression patterns.
    -   Computational complexity increases due to temporal structure.

### Non-Longitudinal Clustering

-   **Definition**: Analyzes cross-sectional data where each observation represents a single time point, treating subjects as static entities.
-   **Key considerations**:
    -   Each observation is treated as independent.
    -   Time is not an explicit factor in the clustering process.
    -   Simpler distance metrics can often be used.
    -   Focus is on identifying patient subtypes based on static characteristics.
    -   Generally less computationally intensive than longitudinal approaches.

### Choosing Between Approaches

-   **Use longitudinal clustering when**:
    -   The temporal evolution of patient conditions is clinically relevant.
    -   You want to identify distinct progression patterns or trajectories.
    -   Treatment response over time is a key research question.
    -   Clinical visits are frequent enough to capture meaningful temporal dynamics.
-   **Use non-longitudinal clustering when**:
    -   The focus is on patient subtypes based on static characteristics.
    -   Temporal patterns are not clinically relevant to the research question.
    -   Data sparsity makes longitudinal analysis unreliable.
    -   Computational resources are limited and simpler methods are preferred.

For the 50,000 emergency psychiatry patients in this study, ***longitudinal clustering*** is appropriate as we're interested in patient trajectories and temporal patterns in their clinical visits.

## Clustering Methods

### Parametric mixture model approaches for longitudinal clustering

For handling irregular timing and covariates in longitudinal data, parametric mixture models like growth mixture modeling are recommended, though distributed inference may be needed for large N.

::: {.callout-note}
## Statistical Assumptions

Assume parametric trajectory forms (e.g., polynomial, spline) and distributional forms (often Gaussian) for within-class variation.
:::

-   **Requirements**: Expect relatively complete data; missingness often assumed Missing At Random (MAR), though some extensions allow Full Information Maximum Likelihood (FIML) estimation. Can incorporate irregular time points if modeled explicitly.
-   **Strengths**: explicitly model trajectories, handle irregular time points, can include covariates.
-   **Weaknesses**: Expectation-Maximization (EM) or Bayesian estimation is slow and memory-intensive. Generally feasible only for N in the tens of thousands.
-   For 50,000 patients, would require distributed or approximate inference and simplified models.
-   Growth mixture modeling [@muthen2000], latent class growth analysis [@jung2008], latent Markov models [@bartolucci2013], group-based trajectory models [@nagin2005].

::: {.callout-warning}
## Scalability Concern

For 50,000 patients, would require distributed or approximate inference and simplified models.
:::

**Key packages**: Python - `sklearn.mixture`, `statsmodels`; R - `lcmm`, `flexmix`, `mclust`, `lavaan`.

### Hidden Markov Models (HMMs)

For capturing state transitions in sequential longitudinal data, HMMs are recommended with approximate training methods to manage scalability for thousands of subjects.

-   **Statistical assumptions**: Assume a latent discrete state process with Markovian dynamics (current state depends only on previous state). Emissions follow chosen parametric distributions.
-   **Requirements**: Typically require complete observed sequences; missing data can be handled probabilistically via emission distributions. Standard HMMs assume evenly spaced observations, though continuous-time variants allow irregular timing.
-   **Strengths**: capture latent states and probabilistic switching patterns, naturally handle categorical/continuous emissions, and irregular timing (in continuous-time variants).
-   **Weaknesses**: parameter estimation via EM or Bayesian inference scales poorly to thousands of subjects; memory and runtime blow up with large state spaces.

::: {.callout-tip}
## Practical Use

Train on subsets or on reduced embeddings, or apply approximate/online HMM training methods.
:::

HMMs and extensions (e.g., hierarchical HMMs, continuous-time HMMs) [@rabiner1989; @jackson2002] are widely used for modeling sequential state transitions.

**Key packages**: Python - `hmmlearn`, `pomegranate`; R - `HMM`, `depmixS4`, `mhsmm`.

### Distance-Based Approaches

For mixed data types and irregular timing, distance-based methods provide flexibility [@liao2005].

```{python}
#| label: distance-example
#| echo: true
#| eval: false

import numpy as np
from scipy.spatial.distance import pdist, squareform
from dtaidistance import dtw

# Example: Dynamic Time Warping for irregular sequences
sequences = [np.array([1, 2, 3, 4]), np.array([1, 3, 4])]
distance = dtw.distance(sequences[0], sequences[1])
print(f"DTW distance: {distance:.2f}")
```

Common distance metrics include:

-   **Dynamic Time Warping (DTW)**: handles irregular timing
-   **Edit distance**: for categorical sequences
-   **Gower distance**: for mixed data types

See @fig-distance for a visualization of DTW alignment.

![Dynamic Time Warping alignment between two sequences](dtw-example.png){#fig-distance}

### Deep Learning Approaches

Neural network architectures can learn representations from irregular longitudinal data [@che2018].

::: {.callout-important}
## Computational Requirements

These methods require GPUs and substantial computational resources for training on 50,000 patients.
:::

```{r}
#| label: lstm-pseudocode
#| echo: true
#| eval: false

# Pseudocode for LSTM-based clustering
model <- keras_model_sequential() %>%
  layer_lstm(units = 128, return_sequences = TRUE) %>%
  layer_dropout(0.2) %>%
  layer_lstm(units = 64) %>%
  layer_dense(units = num_clusters, activation = "softmax")
```

Key architectures:

1.  **LSTM/GRU networks**: capture temporal dependencies
2.  **Transformer models**: handle irregular timing via attention
3.  **Variational autoencoders**: learn latent representations

Cross-reference @tbl-comparison for method comparison.

| Method | Scalability | Irregular Time | Missing Data |
|--------|-------------|----------------|--------------|
| GMM    | Medium      | Yes            | MAR          |
| HMM    | Low         | Limited        | Yes          |
| DTW    | High        | Yes            | No           |
| LSTM   | High        | Yes            | Yes          |

: Comparison of clustering methods {#tbl-comparison}

## Computational Considerations

For N = 50,000 patients:

-   Memory: O(N^2^) distance matrices = ~20GB for float32
-   Time complexity: varies by method
-   Recommended: use approximations (sampling, embeddings)

The computational complexity is O(N^2^) for pairwise distances, which becomes:

$$
\text{Memory} = \frac{N(N-1)}{2} \times 4 \text{ bytes} \approx 5 \text{ GB}
$$ {#eq-memory}

For 50,000 patients, see @eq-memory for memory requirements.

### Inline Calculations

The mean trajectory length is `{python} np.mean([4, 3, 5, 6])` visits, with variance `{python} np.var([4, 3, 5, 6])`.

## Recommendations

Based on the analysis:

::: {.panel-tabset}
## Small Scale

For N < 10,000: Use parametric mixture models with full EM estimation.

## Medium Scale

For 10,000 < N < 50,000: Use HMMs with approximate inference or distance-based methods.

## Large Scale

For N > 50,000: Use deep learning approaches with mini-batch training or approximate nearest neighbor methods.
:::

::: {.content-visible when-format="html"}
## Interactive Elements

This section is only visible in HTML output.

{{< video https://example.com/clustering-tutorial.mp4 >}}
:::

## Conclusion

Longitudinal clustering of 50,000 emergency psychiatry patients requires careful consideration of:

1.  Temporal structure and irregular timing
2.  Missing data mechanisms
3.  Computational scalability
4.  Mixed data types

~~Simple k-means is insufficient~~ for this task; instead, we recommend HMMs or deep learning approaches with appropriate approximations.

## References

::: {#refs}
:::

## Appendix: Code Examples {.appendix}

```{julia}
#| label: julia-example
#| echo: true
#| eval: false

# Julia example for parallel computation
using Distributed
@everywhere using Clustering

# Parallel k-means
results = pmap(1:10) do i
    kmeans(data, k, maxiter=100)
end
```

```{sql}
#| label: sql-query
#| connection: db
#| eval: false

-- Query patient trajectories
SELECT patient_id, visit_date, diagnosis
FROM clinical_visits
WHERE visit_date BETWEEN '2020-01-01' AND '2023-12-31'
ORDER BY patient_id, visit_date;
```

**Mathematical notation**: H~2~O, x^2^, ==highlighted text==, [underlined text]{.underline}

For more details, see [our project website](https://example.com) or contact us at <research@example.com>.
